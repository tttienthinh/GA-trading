{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import pandas as pd\n",
    "import math\n",
    "import os.path\n",
    "import time\n",
    "from binance.client import Client\n",
    "from datetime import timedelta, datetime\n",
    "from dateutil import parser\n",
    "from tqdm import tqdm_notebook #(Optional, used for progress-bars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### API\n",
    "binance_api_key = '0YoXpNjk2J0rwPmIDFlgRuu2fFHKHSADD6qUNoRVTr3N9Rddjdbg3AFP7jzyxvly'    #Enter your own API-key here\n",
    "binance_api_secret = 'rKJZ8XQZGI4D9lTmYztoHmTDPw4fWcNWbT4vEs6edw8qEmBP4QqAYfBmxH6KGWiW' #Enter your own API-secret here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONSTANTS\n",
    "binsizes = {\"1m\": 1, \"5m\": 5, \"1h\": 60, \"1d\": 1440}\n",
    "batch_size = 750\n",
    "client = Client(\"0YoXpNjk2J0rwPmIDFlgRuu2fFHKHSADD6qUNoRVTr3N9Rddjdbg3AFP7jzyxvly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FUNCTIONS\n",
    "def minutes_of_new_data(symbol, kline_size, data, source):\n",
    "    if len(data) > 0:  \n",
    "        old = parser.parse(data[\"timestamp\"].iloc[-1])\n",
    "    elif source == \"binance\": \n",
    "        old = datetime.strptime('1 Jan 2017', '%d %b %Y')\n",
    "    if source == \"binance\": \n",
    "        new = pd.to_datetime(\n",
    "            client.get_klines(symbol=symbol, \n",
    "                                      interval=kline_size)[-1][0], \n",
    "            unit='ms'\n",
    "        )\n",
    "    return old, new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_binance(symbol, kline_size, save = False):\n",
    "    filename = '%s-%s-data.csv' % (symbol, kline_size)\n",
    "    if os.path.isfile(filename): \n",
    "        data_df = pd.read_csv(filename)\n",
    "    else: \n",
    "        data_df = pd.DataFrame()\n",
    "    oldest_point, newest_point = minutes_of_new_data(symbol, \n",
    "                                                     kline_size, \n",
    "                                                     data_df, \n",
    "                                                     source = \"binance\")\n",
    "    delta_min = (newest_point - oldest_point).total_seconds()/60\n",
    "    available_data = math.ceil(delta_min/binsizes[kline_size])\n",
    "    if oldest_point == datetime.strptime('1 Jan 2017', '%d %b %Y'): \n",
    "        print('Downloading all available %s data for %s. \\\n",
    "        Be patient..!' % (kline_size, symbol))\n",
    "    else: \n",
    "        print('Downloading %d minutes of new data available \\\n",
    "        for %s, i.e. %d instances of %s data.' \\\n",
    "              % (delta_min, symbol, available_data, kline_size))\n",
    "    klines = client.get_historical_klines(symbol, \n",
    "                                          kline_size, \n",
    "                                          oldest_point.strftime(\"%d %b %Y %H:%M:%S\"), \n",
    "                                          newest_point.strftime(\"%d %b %Y %H:%M:%S\"))\n",
    "    data = pd.DataFrame(klines, \n",
    "                        columns = ['timestamp', 'open', 'high', 'low', 'close', 'volume', \n",
    "                                   'close_time', 'quote_av', 'trades', 'tb_base_av', \n",
    "                                   'tb_quote_av', 'ignore' ])\n",
    "    data['timestamp'] = pd.to_datetime(data['timestamp'], unit='ms')\n",
    "    if len(data_df) > 0:\n",
    "        temp_df = pd.DataFrame(data)\n",
    "        data_df = data_df.append(temp_df)\n",
    "    else: \n",
    "        data_df = data\n",
    "    data_df.set_index('timestamp', inplace=True)\n",
    "    if save: \n",
    "        data_df.to_csv(filename)\n",
    "    print('All caught up..!')\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_delta_binance(symbol, kline_size, save = False, delta=timedelta(days=7)):\n",
    "    filename = '%s-%s-data.csv' % (symbol, kline_size)\n",
    "    data_df = pd.DataFrame()\n",
    "    oldest_point, newest_point = minutes_of_new_data(symbol, \n",
    "                                                     kline_size, \n",
    "                                                     data_df, \n",
    "                                                     source = \"binance\")\n",
    "    oldest_point = newest_point - delta\n",
    "    delta_min = (newest_point - oldest_point).total_seconds()/60\n",
    "    available_data = math.ceil(delta_min/binsizes[kline_size])\n",
    "    print('Downloading %d minutes of new data available \\\n",
    "    for %s, i.e. %d instances of %s data.' \\\n",
    "          % (delta_min, symbol, available_data, kline_size))\n",
    "    klines = client.get_historical_klines(symbol, \n",
    "                                          kline_size, \n",
    "                                          oldest_point.strftime(\"%d %b %Y %H:%M:%S\"), \n",
    "                                          newest_point.strftime(\"%d %b %Y %H:%M:%S\"))\n",
    "    data = pd.DataFrame(klines, \n",
    "                        columns = ['timestamp', 'open', 'high', 'low', 'close', 'volume', \n",
    "                                   'close_time', 'quote_av', 'trades', 'tb_base_av', \n",
    "                                   'tb_quote_av', 'ignore' ])\n",
    "    data['timestamp'] = pd.to_datetime(data['timestamp'], unit='ms')\n",
    "    if len(data_df) > 0:\n",
    "        temp_df = pd.DataFrame(data)\n",
    "        data_df = data_df.append(temp_df)\n",
    "    else: \n",
    "        data_df = data\n",
    "    data_df.set_index('timestamp', inplace=True)\n",
    "    if save: \n",
    "        data_df.to_csv(filename)\n",
    "    print('All caught up..!')\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 86400 minutes of new data available     for BTCUSDT, i.e. 1440 instances of 1h data.\n",
      "All caught up..!\n"
     ]
    }
   ],
   "source": [
    "# For Binance\n",
    "binance_symbols = [\"BTCUSDT\"]\n",
    "for symbol in binance_symbols:\n",
    "    get_delta_binance(symbol, '1h', save = True, delta=timedelta(days=60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
